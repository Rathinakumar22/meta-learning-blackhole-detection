{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6e29ea-7661-4e59-8e52-f64982b7a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (404134, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>length</th>\n",
       "      <th>info</th>\n",
       "      <th>transmission_rate_per_1000_ms</th>\n",
       "      <th>reception_rate_per_1000_ms</th>\n",
       "      <th>transmission_average_per_sec</th>\n",
       "      <th>reception_average_per_sec</th>\n",
       "      <th>transmission_count_per_sec</th>\n",
       "      <th>reception_count_per_sec</th>\n",
       "      <th>transmission_total_duration_per_sec</th>\n",
       "      <th>reception_total_duration_per_sec</th>\n",
       "      <th>dao</th>\n",
       "      <th>dis</th>\n",
       "      <th>dio</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.539313</td>\n",
       "      <td>0.570032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.264704</td>\n",
       "      <td>0.530547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.462516</td>\n",
       "      <td>0.501327</td>\n",
       "      <td>0.671768</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.546376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690115</td>\n",
       "      <td>Blackhole</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634105</td>\n",
       "      <td>0.585425</td>\n",
       "      <td>0.553276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.615377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time  source  destination  length  info  transmission_rate_per_1000_ms  \\\n",
       "0  0.037      39         9999     0.0   1.0                       0.000000   \n",
       "1  0.037      39         9999     0.0   1.0                       0.000000   \n",
       "2  0.038      39         9999     0.0   1.0                       0.671176   \n",
       "3  0.045      39         9999     0.0   1.0                       0.000000   \n",
       "4  0.046      39         9999     0.0   1.0                       0.000000   \n",
       "\n",
       "   reception_rate_per_1000_ms  transmission_average_per_sec  \\\n",
       "0                    0.671176                      0.000000   \n",
       "1                    0.649873                      0.000000   \n",
       "2                    0.652361                      0.462516   \n",
       "3                    0.633786                      0.000000   \n",
       "4                    0.630378                      0.000000   \n",
       "\n",
       "   reception_average_per_sec  transmission_count_per_sec  \\\n",
       "0                   0.499879                    0.000000   \n",
       "1                   0.505234                    0.000000   \n",
       "2                   0.501327                    0.671768   \n",
       "3                   0.517346                    0.000000   \n",
       "4                   0.538789                    0.000000   \n",
       "\n",
       "   reception_count_per_sec  transmission_total_duration_per_sec  \\\n",
       "0                 0.671176                             0.539313   \n",
       "1                 0.649873                             0.264704   \n",
       "2                 0.652361                             0.546376   \n",
       "3                 0.634105                             0.585425   \n",
       "4                 0.630378                             0.443171   \n",
       "\n",
       "   reception_total_duration_per_sec  dao  dis       dio   category  label  \n",
       "0                          0.570032  0.0  0.0  0.000000     Normal      0  \n",
       "1                          0.530547  0.0  0.0  0.000000     Normal      0  \n",
       "2                          1.000000  0.0  0.0  0.690115  Blackhole      1  \n",
       "3                          0.553276  0.0  0.0  0.000000     Normal      0  \n",
       "4                          0.615377  0.0  0.0  0.000000     Normal      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "data = pd.read_csv('blackhole.csv')\n",
    "print(f'Dataset shape: {data.shape}')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6207df73-9b5e-490e-93ae-dddd21f61eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                                   float64\n",
      "source                                   int64\n",
      "destination                              int64\n",
      "length                                 float64\n",
      "info                                   float64\n",
      "transmission_rate_per_1000_ms          float64\n",
      "reception_rate_per_1000_ms             float64\n",
      "transmission_average_per_sec           float64\n",
      "reception_average_per_sec              float64\n",
      "transmission_count_per_sec             float64\n",
      "reception_count_per_sec                float64\n",
      "transmission_total_duration_per_sec    float64\n",
      "reception_total_duration_per_sec       float64\n",
      "dao                                    float64\n",
      "dis                                    float64\n",
      "dio                                    float64\n",
      "category                                object\n",
      "label                                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "normal = data[data['label'] == 0]\n",
    "blackhole = data[data['label'] == 1]\n",
    "\n",
    "# Upsample minority class (blackhole)\n",
    "upsampled = resample(blackhole, \n",
    "                               replace=True,    # sample with replacement\n",
    "                               n_samples=len(normal), # match number in majority class\n",
    "                               random_state=42) # reproducible results\n",
    "\n",
    "# Combine majority and upsampled minority\n",
    "# Identify and inspect categorical columns\n",
    "print(upsampled.dtypes)\n",
    "\n",
    "# If there are any categorical columns, convert them to numerical using one-hot encoding\n",
    "upsampled_encoded = pd.get_dummies(upsampled, drop_first=True)\n",
    "\n",
    "# Preprocessing: feature scaling after encoding\n",
    "X = upsampled_encoded.drop('label', axis=1)\n",
    "y = upsampled_encoded['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9108b818-afa5-4a2d-a078-4596dfb022ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Siamese Network for Metric-Based Meta-Learning\n",
    "class SiameseNetwork(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc1 = layers.Dense(64, activation='relu')\n",
    "        self.fc2 = layers.Dense(32, activation='relu')\n",
    "        self.out = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        return self.out(x)\n",
    "\n",
    "# Model training setup for Siamese Network\n",
    "# Model training setup for Siamese Network\n",
    "def siamese_train_step(model, optimizer, X1, X2, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass for both inputs\n",
    "        predictions1 = model(X1)\n",
    "        predictions2 = model(X2)\n",
    "        \n",
    "        # Calculate the distance between the two predictions\n",
    "        distance = tf.abs(predictions1 - predictions2)\n",
    "\n",
    "        # Squeeze to ensure the shape is correct and reshape\n",
    "        distance = tf.reshape(distance, [-1, 1])  # Ensure shape is (batch_size, 1)\n",
    "        y = tf.reshape(y, [-1, 1])  # Ensure target shape is also (batch_size, 1)\n",
    "        \n",
    "        # Loss is binary cross-entropy based on distance\n",
    "        loss = tf.keras.losses.binary_crossentropy(y, distance)\n",
    "    \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Federated Learning setup remains unchanged\n",
    "def federated_train(X_splits, y_splits, num_rounds=10):\n",
    "    global_model = SiameseNetwork()  # Use the Siamese model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"Round {round_num + 1}\")\n",
    "        for X, y in zip(X_splits, y_splits):\n",
    "            # Split the input data into pairs for the Siamese Network\n",
    "            # Here we assume X is structured as pairs for demonstration\n",
    "            X1, X2 = X[:, :X.shape[1] // 2], X[:, X.shape[1] // 2:]  # Example pair splitting\n",
    "            siamese_train_step(global_model, optimizer, X1, X2, y)\n",
    "\n",
    "    return global_model\n",
    "\n",
    "# Simulate distributed datasets for federated learning\n",
    "X_train = np.random.rand(1000, 18)  # Example input data with 18 features\n",
    "y_train = np.random.randint(0, 2, size=(1000, 1))  # Example binary labels\n",
    "\n",
    "X_splits = np.array_split(X_train, 5)  # Split data for 5 clients\n",
    "y_splits = np.array_split(y_train, 5)\n",
    "\n",
    "# Federated training\n",
    "global_model = federated_train(X_splits, y_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b350fd-7ae2-463b-adc8-bc4cb9711910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n",
      "Confusion Matrix:\n",
      "[[ 90   0]\n",
      " [110   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62        90\n",
      "           1       0.00      0.00      0.00       110\n",
      "\n",
      "    accuracy                           0.45       200\n",
      "   macro avg       0.23      0.50      0.31       200\n",
      "weighted avg       0.20      0.45      0.28       200\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Siamese Network for Metric-Based Meta-Learning\n",
    "class SiameseNetwork(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc1 = layers.Dense(64, activation='relu')\n",
    "        self.fc2 = layers.Dense(32, activation='relu')\n",
    "        self.out = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        return self.out(x)\n",
    "\n",
    "# Model training setup for Siamese Network\n",
    "def siamese_train_step(model, optimizer, X1, X2, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass for both inputs\n",
    "        predictions1 = model(X1)\n",
    "        predictions2 = model(X2)\n",
    "\n",
    "        # Calculate the distance between the two predictions\n",
    "        distance = tf.abs(predictions1 - predictions2)\n",
    "\n",
    "        # Ensure correct shape\n",
    "        distance = tf.reshape(distance, [-1, 1])  # Ensure shape is (batch_size, 1)\n",
    "        y = tf.reshape(y, [-1, 1])  # Ensure target shape is also (batch_size, 1)\n",
    "\n",
    "        # Loss is binary cross-entropy based on distance\n",
    "        loss = tf.keras.losses.binary_crossentropy(y, distance)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Federated Learning setup remains unchanged\n",
    "def federated_train(X_splits, y_splits, num_rounds=10):\n",
    "    global_model = SiameseNetwork()  # Use the Siamese model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"Round {round_num + 1}\")\n",
    "        for X, y in zip(X_splits, y_splits):\n",
    "            # Split the input data into pairs for the Siamese Network\n",
    "            # Here we assume X is structured as pairs for demonstration\n",
    "            X1, X2 = X[:, :X.shape[1] // 2], X[:, X.shape[1] // 2:]  # Example pair splitting\n",
    "            siamese_train_step(global_model, optimizer, X1, X2, y)\n",
    "\n",
    "    return global_model\n",
    "\n",
    "# Simulate distributed datasets for federated learning\n",
    "X_train = np.random.rand(1000, 18)  # Example input data with 18 features\n",
    "y_train = np.random.randint(0, 2, size=(1000, 1))  # Example binary labels\n",
    "\n",
    "X_splits = np.array_split(X_train, 5)  # Split data for 5 clients\n",
    "y_splits = np.array_split(y_train, 5)\n",
    "\n",
    "# Federated training\n",
    "global_model = federated_train(X_splits, y_splits)\n",
    "\n",
    "# Inference on test data\n",
    "def create_pairs(X):\n",
    "    # Assuming X is structured correctly for Siamese network pairing\n",
    "    # For simplicity, we use pairs of random slices\n",
    "    X1 = X[:, :X.shape[1] // 2]  # First half\n",
    "    X2 = X[:, X.shape[1] // 2:]  # Second half\n",
    "    return X1, X2\n",
    "\n",
    "# Prepare a test set\n",
    "X_test = np.random.rand(200, 18)  # Example test data with 18 features\n",
    "y_test = np.random.randint(0, 2, size=(200, 1))  # Example binary labels for test\n",
    "\n",
    "# Create pairs for testing\n",
    "X1_test, X2_test = create_pairs(X_test)\n",
    "\n",
    "# Make predictions\n",
    "predictions1 = global_model(X1_test)\n",
    "predictions2 = global_model(X2_test)\n",
    "\n",
    "# Calculate the absolute distance\n",
    "distance = tf.abs(predictions1 - predictions2)\n",
    "y_pred = tf.round(tf.squeeze(distance))  # Convert to binary predictions\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a000cd-aa88-408e-9b80-dd0870d4b09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
