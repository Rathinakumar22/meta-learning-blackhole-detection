{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2009ff-5c11-4a1e-ab20-93e2d24f9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (404134, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>length</th>\n",
       "      <th>info</th>\n",
       "      <th>transmission_rate_per_1000_ms</th>\n",
       "      <th>reception_rate_per_1000_ms</th>\n",
       "      <th>transmission_average_per_sec</th>\n",
       "      <th>reception_average_per_sec</th>\n",
       "      <th>transmission_count_per_sec</th>\n",
       "      <th>reception_count_per_sec</th>\n",
       "      <th>transmission_total_duration_per_sec</th>\n",
       "      <th>reception_total_duration_per_sec</th>\n",
       "      <th>dao</th>\n",
       "      <th>dis</th>\n",
       "      <th>dio</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.539313</td>\n",
       "      <td>0.570032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.264704</td>\n",
       "      <td>0.530547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.462516</td>\n",
       "      <td>0.501327</td>\n",
       "      <td>0.671768</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.546376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690115</td>\n",
       "      <td>Blackhole</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634105</td>\n",
       "      <td>0.585425</td>\n",
       "      <td>0.553276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046</td>\n",
       "      <td>39</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.615377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time  source  destination  length  info  transmission_rate_per_1000_ms  \\\n",
       "0  0.037      39         9999     0.0   1.0                       0.000000   \n",
       "1  0.037      39         9999     0.0   1.0                       0.000000   \n",
       "2  0.038      39         9999     0.0   1.0                       0.671176   \n",
       "3  0.045      39         9999     0.0   1.0                       0.000000   \n",
       "4  0.046      39         9999     0.0   1.0                       0.000000   \n",
       "\n",
       "   reception_rate_per_1000_ms  transmission_average_per_sec  \\\n",
       "0                    0.671176                      0.000000   \n",
       "1                    0.649873                      0.000000   \n",
       "2                    0.652361                      0.462516   \n",
       "3                    0.633786                      0.000000   \n",
       "4                    0.630378                      0.000000   \n",
       "\n",
       "   reception_average_per_sec  transmission_count_per_sec  \\\n",
       "0                   0.499879                    0.000000   \n",
       "1                   0.505234                    0.000000   \n",
       "2                   0.501327                    0.671768   \n",
       "3                   0.517346                    0.000000   \n",
       "4                   0.538789                    0.000000   \n",
       "\n",
       "   reception_count_per_sec  transmission_total_duration_per_sec  \\\n",
       "0                 0.671176                             0.539313   \n",
       "1                 0.649873                             0.264704   \n",
       "2                 0.652361                             0.546376   \n",
       "3                 0.634105                             0.585425   \n",
       "4                 0.630378                             0.443171   \n",
       "\n",
       "   reception_total_duration_per_sec  dao  dis       dio   category  label  \n",
       "0                          0.570032  0.0  0.0  0.000000     Normal      0  \n",
       "1                          0.530547  0.0  0.0  0.000000     Normal      0  \n",
       "2                          1.000000  0.0  0.0  0.690115  Blackhole      1  \n",
       "3                          0.553276  0.0  0.0  0.000000     Normal      0  \n",
       "4                          0.615377  0.0  0.0  0.000000     Normal      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "data = pd.read_csv('blackhole.csv')\n",
    "print(f'Dataset shape: {data.shape}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc023cd0-903f-4d68-9872-12c709b5a137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                                   float64\n",
      "source                                   int64\n",
      "destination                              int64\n",
      "length                                 float64\n",
      "info                                   float64\n",
      "transmission_rate_per_1000_ms          float64\n",
      "reception_rate_per_1000_ms             float64\n",
      "transmission_average_per_sec           float64\n",
      "reception_average_per_sec              float64\n",
      "transmission_count_per_sec             float64\n",
      "reception_count_per_sec                float64\n",
      "transmission_total_duration_per_sec    float64\n",
      "reception_total_duration_per_sec       float64\n",
      "dao                                    float64\n",
      "dis                                    float64\n",
      "dio                                    float64\n",
      "category                                object\n",
      "label                                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "normal = data[data['label'] == 0]\n",
    "blackhole = data[data['label'] == 1]\n",
    "\n",
    "# Upsample minority class (blackhole)\n",
    "upsampled = resample(blackhole, \n",
    "                               replace=True,    # sample with replacement\n",
    "                               n_samples=len(normal), # match number in majority class\n",
    "                               random_state=42) # reproducible results\n",
    "\n",
    "# Combine majority and upsampled minority\n",
    "# Identify and inspect categorical columns\n",
    "print(upsampled.dtypes)\n",
    "\n",
    "# If there are any categorical columns, convert them to numerical using one-hot encoding\n",
    "upsampled_encoded = pd.get_dummies(upsampled, drop_first=True)\n",
    "\n",
    "# Preprocessing: feature scaling after encoding\n",
    "X = upsampled_encoded.drop('label', axis=1)\n",
    "y = upsampled_encoded['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1e2c1a-61b9-4592-a556-8ca940a4ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n",
      "Round 10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Bayesian Neural Network Model using Monte Carlo Dropout\n",
    "class BayesianNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BayesianNN, self).__init__()\n",
    "        self.fc1 = layers.Dense(64, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)  # Dropout layer for uncertainty\n",
    "        self.fc2 = layers.Dense(32, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)  # Dropout layer for uncertainty\n",
    "        self.out = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.dropout1(x, training=training)  # Apply dropout during training\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x, training=training)  # Apply dropout during training\n",
    "        return self.out(x)\n",
    "\n",
    "# Model training setup for Bayesian Neural Network\n",
    "def bayesian_train_step(model, optimizer, X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(X, training=True)  # Enable training mode for dropout\n",
    "        predictions = tf.squeeze(predictions)  # Ensure predictions have the same shape as y\n",
    "        loss = tf.keras.losses.binary_crossentropy(y, predictions)\n",
    "        \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Federated Learning setup remains unchanged\n",
    "def federated_train(X_splits, y_splits, num_rounds=10):\n",
    "    global_model = BayesianNN()  # Use BayesianNN model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"Round {round_num + 1}\")\n",
    "        for X, y in zip(X_splits, y_splits):\n",
    "            bayesian_train_step(global_model, optimizer, X, y)\n",
    "\n",
    "    return global_model\n",
    "\n",
    "# Simulate distributed datasets for federated learning\n",
    "X_splits = np.array_split(X_train, 5)\n",
    "y_splits = np.array_split(y_train, 5)\n",
    "\n",
    "# Federated training\n",
    "global_model = federated_train(X_splits, y_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7031aea6-2728-4a88-b814-399baf290e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[53971]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     53971\n",
      "\n",
      "    accuracy                           1.00     53971\n",
      "   macro avg       1.00      1.00      1.00     53971\n",
      "weighted avg       1.00      1.00      1.00     53971\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = global_model(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2390179-858e-4fc6-aeb7-46cbd3a43dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
